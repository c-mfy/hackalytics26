<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>research — speechwrite</title>
  <style>
    *, *::before, *::after { margin:0; padding:0; box-sizing:border-box; }

    /* same token set as index.html — keep these in sync */
    :root {
      --navy:  #010e1f;
      --navy2: #012347;
      --blue:  #1188F7;
      --blue2: #0A64B8;
      --lblue: #7ACCFF;
      --lcyan: #75FFF8;
      --xlight:#EBF1FF;
      --yellow:#FFE19E;
      --dim:   rgba(122,204,255,0.4);
      --border:rgba(17,136,247,0.16);
      --font:  'Microsoft Sans Serif','Segoe UI',-apple-system,BlinkMacSystemFont,sans-serif;
    }
    html { scroll-behavior:smooth; }
    body { background:var(--navy); color:var(--xlight); font-family:var(--font); font-size:12.5px; line-height:1.8; overflow-x:hidden; }

    /* hero — padding-driven height so it scales naturally at any viewport size
       nav is fixed at ~68px tall, so 130px top padding always clears it */
    .hero-section {
      position:relative;
      overflow:hidden; display:flex; align-items:flex-end;
      padding: 130px 0 60px 0;
    }

    /* animated gradient bg — three keyframe states shift the radial center */
    .hero-bg {
      position:absolute; inset:0;
      background: radial-gradient(ellipse 120% 100% at 50% 110%, #0a2847 0%, #051428 40%, #010e1f 70%);
      animation: heroPulse 10s ease-in-out infinite alternate;
    }
    @keyframes heroPulse {
      0%   { background: radial-gradient(ellipse 120% 100% at 40% 110%, #0d3060 0%, #061830 40%, #010e1f 70%); }
      50%  { background: radial-gradient(ellipse 140% 110% at 60% 105%, #0a2848 0%, #04162c 45%, #010c1a 70%); }
      100% { background: radial-gradient(ellipse 120% 100% at 50% 115%, #0e3570 0%, #071c38 40%, #011020 70%); }
    }

    /* ::before — blue glow orbs layered on top of the bg */
    .hero-bg::before {
      content:''; position:absolute; inset:0;
      background:
        radial-gradient(ellipse 50% 35% at 25% 70%, rgba(17,136,247,0.12) 0%, transparent 60%),
        radial-gradient(ellipse 40% 30% at 75% 50%, rgba(122,204,255,0.07) 0%, transparent 60%),
        radial-gradient(ellipse 30% 40% at 50% 90%, rgba(10,100,184,0.15) 0%, transparent 55%);
      animation: heroGlow 7s ease-in-out infinite alternate;
    }
    @keyframes heroGlow {
      0%   { opacity:0.6; transform:scale(1); }
      100% { opacity:1;   transform:scale(1.04) translateY(-1%); }
    }

    /* ::after — horizontal light streak that drifts vertically */
    .hero-bg::after {
      content:''; position:absolute;
      bottom:30%; left:0; right:0; height:1px;
      background: linear-gradient(to right, transparent 0%, rgba(17,136,247,0.2) 30%, rgba(122,204,255,0.3) 50%, rgba(17,136,247,0.2) 70%, transparent 100%);
      animation: streakMove 6s ease-in-out infinite alternate;
    }
    @keyframes streakMove { 0%{bottom:28%;opacity:.5} 100%{bottom:33%;opacity:1} }

    .hero-content { position:relative; z-index:2; width:100%; max-width:780px; padding:0 56px; }
    /* ghost title — intentionally semi-transparent, gradient text */
    .hero-title {
      font-size:clamp(48px,9vw,118px); font-weight:700; letter-spacing:0.01em; line-height:0.9;
      background: linear-gradient(160deg, rgba(235,241,255,0.3) 0%, rgba(122,204,255,0.2) 50%, rgba(17,136,247,0.15) 100%);
      -webkit-background-clip:text; -webkit-text-fill-color:transparent;
    }

    /* fixed nav — just the logo/home link, no other items on this page */
    nav {
      position:fixed; top:0; left:0; right:0; z-index:50;
      display:flex; align-items:center; padding:18px 36px;
      background:rgba(1,10,22,0.6); backdrop-filter:blur(20px);
      border-bottom:1px solid rgba(17,136,247,0.08);
    }
    .logo-wrap { display:flex; align-items:center; gap:10px; text-decoration:none; cursor:pointer; }
    .logo-icon { width:30px; height:30px; border-radius:7px; background:linear-gradient(135deg,rgba(17,136,247,0.25),rgba(117,255,248,0.08)); border:1px solid rgba(17,136,247,0.28); display:flex; align-items:center; justify-content:center; font-size:13px; color:var(--lblue); }
    .logo-name { font-size:15px; font-weight:600; }
    .logo-name .w1 { color:var(--xlight); }
    .logo-name .w2 { background:linear-gradient(90deg,var(--blue) 0%,var(--lblue) 100%); -webkit-background-clip:text; -webkit-text-fill-color:transparent; }

    /* centered content column */
    main { position:relative; z-index:1; max-width:780px; margin:0 auto; padding:72px 56px 100px; }

    .section { margin-bottom:72px; }

    /* section headings split into two spans:
       .hl = gradient colored first syllable, .dm = muted rest */
    .section-heading {
      font-size:clamp(18px,2.5vw,26px); font-weight:600; letter-spacing:0.01em; margin-bottom:28px;
    }
    .section-heading .hl {
      background:linear-gradient(90deg,var(--blue) 0%,var(--lblue) 100%);
      -webkit-background-clip:text; -webkit-text-fill-color:transparent;
    }
    .section-heading .dm { color:rgba(235,241,255,0.45); }

    p { color:rgba(235,241,255,0.62); font-size:12px; margin-bottom:18px; max-width:640px; line-height:1.82; }

    /* floating glass chart cards — drawn on canvas by drawScatterChart() in JS
       right float for methodology section, left float for calculations */
    .chart-float-right { float:right; width:min(280px,42%); margin:0 0 20px 28px; background:rgba(1,20,42,0.6); border:1px solid var(--border); border-radius:12px; padding:16px; backdrop-filter:blur(12px); box-shadow:0 8px 32px rgba(0,0,0,.3),inset 0 1px 0 rgba(235,241,255,0.04); }
    .chart-float-left  { float:left;  width:min(280px,42%); margin:0 28px 20px 0; background:rgba(1,20,42,0.6); border:1px solid var(--border); border-radius:12px; padding:16px; backdrop-filter:blur(12px); box-shadow:0 8px 32px rgba(0,0,0,.3),inset 0 1px 0 rgba(235,241,255,0.04); }
    .chart-label-row { display:flex; justify-content:space-between; align-items:center; margin-bottom:10px; }
    .chart-year { font-size:8px; letter-spacing:.14em; color:var(--dim); }
    .chart-unit { font-size:8px; letter-spacing:.1em; color:var(--dim); }
    .mini-chart { width:100%; height:120px; display:block; }
    .chart-axis-labels { display:flex; justify-content:space-between; margin-top:4px; }
    .axis-label { font-size:7px; color:rgba(122,204,255,.25); letter-spacing:.06em; }
    /* clearfix needed because children are floated */
    .clearfix::after { content:''; display:block; clear:both; }

    .section-divider { border:none; border-top:1px solid rgba(17,136,247,0.1); margin:64px 0; }

    ::-webkit-scrollbar { width:4px; }
    ::-webkit-scrollbar-track { background:var(--navy); }
    ::-webkit-scrollbar-thumb { background:rgba(17,136,247,0.15); border-radius:2px; }

    /* ── equation blocks ─────────────────────────────────────────────────────── */
    .eq-block {
      background: rgba(1,20,42,0.7);
      border: 1px solid rgba(17,136,247,0.22);
      border-left: 3px solid var(--blue);
      border-radius: 10px;
      padding: 24px 28px;
      margin: 28px 0;
      backdrop-filter: blur(12px);
      box-shadow: 0 8px 32px rgba(0,0,0,.35), inset 0 1px 0 rgba(235,241,255,0.04);
    }
    .eq-label {
      font-size: 8px; letter-spacing: .16em; color: var(--lblue);
      text-transform: uppercase; margin-bottom: 14px; opacity: .7;
    }
    .eq-main {
      font-size: clamp(18px, 3vw, 26px);
      font-weight: 700;
      color: var(--xlight);
      letter-spacing: .02em;
      line-height: 1.5;
    }
    .eq-main .eq-frac {
      display: inline-flex; flex-direction: column; align-items: center;
      vertical-align: middle; margin: 0 6px;
    }
    .eq-main .eq-num { border-bottom: 2px solid rgba(122,204,255,0.55); padding-bottom: 2px; font-size: .9em; }
    .eq-main .eq-den { padding-top: 2px; font-size: .9em; }
    .eq-main .hl  { background: linear-gradient(90deg, var(--blue) 0%, var(--lblue) 100%); -webkit-background-clip:text; -webkit-text-fill-color:transparent; }
    .eq-main .yl  { color: var(--yellow); }
    .eq-desc {
      margin-top: 14px; font-size: 11px; color: rgba(235,241,255,0.45);
      line-height: 1.7; max-width: 560px;
    }
    .eq-desc span { color: rgba(235,241,255,0.7); font-weight:600; }

    /* ── HMM diagram wrapper ─────────────────────────────────────────────────── */
    .hmm-wrap {
      background: rgba(1,20,42,0.65);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 28px 20px 20px;
      margin: 28px 0;
      backdrop-filter: blur(12px);
      box-shadow: 0 8px 32px rgba(0,0,0,.3), inset 0 1px 0 rgba(235,241,255,0.04);
      overflow: hidden;
    }
    .hmm-title {
      font-size: 8px; letter-spacing: .16em; color: var(--lblue);
      text-transform: uppercase; margin-bottom: 18px; opacity: .7;
    }
    .hmm-svg { width: 100%; height: auto; display: block; }
  </style>
</head>
<body>

<!-- fixed nav — logo only, links back to home -->
<nav>
  <a class="logo-wrap" href="/">
    <div class="logo-icon">✦</div>
    <div class="logo-name"><span class="w1">speech</span><span class="w2">write</span></div>
  </a>
</nav>

<!-- hero — animated gradient bg, ghost title text -->
<div class="hero-section">
  <div class="hero-bg"></div>
  <div class="hero-content">
    <div class="hero-title">Speech Right<br>with<br>Speech Write</div>
  </div>
</div>

<main>

  <!-- audience section -->
  <div class="section">
    <h2 class="section-heading"><span class="hl">audi</span><span class="dm">ence</span></h2>
    <p>Speech recognition is a core deliverable in the entertainment industry. Game studios embed real-time transcription into dialogue systems and accessibility overlays. Streaming platforms rely on auto-generated captions to meet compliance requirements. Interactive experiences in games, movies, and theme parks depend on whether the model can accurately parse what a speaker said.</p>
    <p>These pipelines were rarely designed with accent diversity in mind. A caption engine trained on American English will struggle with Australian English vowel shifts, Indian English retroflex consonants, or South African English rhythm, producing errors that mislead audiences. The same problem appears in university lecture recordings, where a professor's regional accent combined with domain-specific terminology defeats off-the-shelf transcription services.</p>
    <p>SpeechWrite targets the teams who build and QA these systems. We surface which phonemes a model consistently mishears, broken down by accent, giving engineers a map of where their pipeline is biased. Teams can use this to prioritize retraining data, adjust confidence thresholds, or flag segments for human review.</p>
  </div>

  <hr class="section-divider" />

  <!-- methodology section -->
  <div class="section">
    <h2 class="section-heading"><span class="hl">meth</span><span class="dm">odology</span></h2>
    <p>Speech-to-text systems convert audio into words by first decomposing speech into phonemes, the smallest meaningful sound units. English uses 39 canonical phonemes covering all vowel and consonant classes. A model maps acoustic features from the waveform onto these units and assembles probable word sequences. The accuracy of that mapping across different accents is what SpeechWrite measures.</p>
    <p>Our audio corpus comes from Mozilla's Common Voice dataset, an open-source collection of crowd-sourced English recordings. We selected clips from five accent groups: American English (ae), Australian English (au), Canadian English (ca), Indian English (in), and South African English (sa). Each clip includes a validated human transcript that serves as the ground truth reference.</p>
    <p>To transcribe each clip we use OpenAI's Whisper model via the GPT-4o-mini transcription API. Whisper represents the class of large-scale models that game studios, streaming platforms, and lecture capture services typically evaluate or deploy. Running the same audio through Whisper five times and averaging the error scores gives a stable per-clip Word Error Rate before phoneme-level analysis.</p>
    <p>Once we have the reference transcript and the Whisper prediction, we convert each to its phoneme sequence using the Python Pronouncing library, which maps English words to ARPAbet representations across the 39-phoneme inventory. We align the two sequences and classify each position as equal (correct), substitute (wrong phoneme), or delete (phoneme in reference but missing from prediction). Insertions are excluded because Whisper occasionally hallucinates tokens with no counterpart in the source audio, and counting those would conflate over-generation with accent-driven misrecognition.</p>
    <p>Each substitution and deletion is recorded against the specific phoneme missed and tagged with the speaker's accent group, building a phoneme-level error frequency table that drives the SpeechWrite dashboard.</p>
  </div>

  <hr class="section-divider" />

  <!-- calculations section -->
  <div class="section">
    <h2 class="section-heading"><span class="hl">calcu</span><span class="dm">lations</span></h2>
    <p>The backbone of speech recognition is the Hidden Markov Model. Each phoneme is a hidden state, not directly observable from the audio, while acoustic features of the waveform are the observable emissions. The model learns transition probabilities between phoneme states and emission probabilities linking acoustic frames to phoneme identities. Inference finds the most likely phoneme sequence given the observed audio, which is why accent-driven acoustic variation causes it to select the wrong state.</p>

    <!-- HMM diagram -->
    <div class="hmm-wrap">
      <div class="hmm-title">Hidden Markov Model: phoneme state transitions</div>
      <svg class="hmm-svg" viewBox="0 0 680 260" xmlns="http://www.w3.org/2000/svg" font-family="'Microsoft Sans Serif',sans-serif">
        <defs>
          <marker id="arr" markerWidth="8" markerHeight="8" refX="7" refY="3" orient="auto">
            <path d="M0,0 L0,6 L8,3 z" fill="rgba(17,136,247,0.7)"/>
          </marker>
          <marker id="arr-emit" markerWidth="8" markerHeight="8" refX="7" refY="3" orient="auto">
            <path d="M0,0 L0,6 L8,3 z" fill="rgba(122,204,255,0.5)"/>
          </marker>
          <radialGradient id="stateGrad" cx="50%" cy="35%" r="60%">
            <stop offset="0%" stop-color="rgba(17,136,247,0.28)"/>
            <stop offset="100%" stop-color="rgba(1,20,42,0.9)"/>
          </radialGradient>
          <radialGradient id="obsGrad" cx="50%" cy="35%" r="60%">
            <stop offset="0%" stop-color="rgba(122,204,255,0.18)"/>
            <stop offset="100%" stop-color="rgba(1,14,31,0.9)"/>
          </obsGrad>
          <filter id="glow">
            <feGaussianBlur stdDeviation="3" result="blur"/>
            <feMerge><feMergeNode in="blur"/><feMergeNode in="SourceGraphic"/></feMerge>
          </filter>
        </defs>

        <!-- ── HIDDEN LAYER label ── -->
        <text x="14" y="105" font-size="8" fill="rgba(122,204,255,0.35)" letter-spacing="2" text-anchor="start">HIDDEN STATES</text>
        <!-- ── OBSERVABLE LAYER label ── -->
        <text x="14" y="220" font-size="8" fill="rgba(122,204,255,0.25)" letter-spacing="2" text-anchor="start">OBSERVATIONS</text>

        <!-- ── state circles ── cx positions: 160, 300, 440, 580 ── -->
        <!-- State 1: /AH/ -->
        <circle cx="160" cy="108" r="38" fill="url(#stateGrad)" stroke="rgba(17,136,247,0.55)" stroke-width="1.5" filter="url(#glow)"/>
        <text x="160" y="103" text-anchor="middle" font-size="13" font-weight="700" fill="#7ACCFF">/AH/</text>
        <text x="160" y="119" text-anchor="middle" font-size="8" fill="rgba(235,241,255,0.4)">schwa</text>

        <!-- State 2: /T/ -->
        <circle cx="300" cy="108" r="38" fill="url(#stateGrad)" stroke="rgba(17,136,247,0.55)" stroke-width="1.5" filter="url(#glow)"/>
        <text x="300" y="103" text-anchor="middle" font-size="13" font-weight="700" fill="#7ACCFF">/T/</text>
        <text x="300" y="119" text-anchor="middle" font-size="8" fill="rgba(235,241,255,0.4)">stop</text>

        <!-- State 3: /IH/ -->
        <circle cx="440" cy="108" r="38" fill="url(#stateGrad)" stroke="rgba(17,136,247,0.55)" stroke-width="1.5" filter="url(#glow)"/>
        <text x="440" y="103" text-anchor="middle" font-size="13" font-weight="700" fill="#7ACCFF">/IH/</text>
        <text x="440" y="119" text-anchor="middle" font-size="8" fill="rgba(235,241,255,0.4)">short-i</text>

        <!-- State 4: /N/ -->
        <circle cx="580" cy="108" r="38" fill="url(#stateGrad)" stroke="rgba(17,136,247,0.55)" stroke-width="1.5" filter="url(#glow)"/>
        <text x="580" y="103" text-anchor="middle" font-size="13" font-weight="700" fill="#7ACCFF">/N/</text>
        <text x="580" y="119" text-anchor="middle" font-size="8" fill="rgba(235,241,255,0.4)">nasal</text>

        <!-- ── transition arrows between states ── -->
        <!-- 1→2 -->
        <line x1="199" y1="104" x2="260" y2="104" stroke="rgba(17,136,247,0.65)" stroke-width="1.4" marker-end="url(#arr)"/>
        <text x="229" y="96" text-anchor="middle" font-size="8.5" font-weight="700" fill="rgba(255,225,158,0.85)">a₁₂</text>

        <!-- 2→3 -->
        <line x1="339" y1="104" x2="400" y2="104" stroke="rgba(17,136,247,0.65)" stroke-width="1.4" marker-end="url(#arr)"/>
        <text x="369" y="96" text-anchor="middle" font-size="8.5" font-weight="700" fill="rgba(255,225,158,0.85)">a₂₃</text>

        <!-- 3→4 -->
        <line x1="479" y1="104" x2="540" y2="104" stroke="rgba(17,136,247,0.65)" stroke-width="1.4" marker-end="url(#arr)"/>
        <text x="509" y="96" text-anchor="middle" font-size="8.5" font-weight="700" fill="rgba(255,225,158,0.85)">a₃₄</text>

        <!-- self-loops -->
        <path d="M148,71 C132,42 188,42 172,71" fill="none" stroke="rgba(17,136,247,0.4)" stroke-width="1.2" marker-end="url(#arr)"/>
        <path d="M288,71 C272,42 328,42 312,71" fill="none" stroke="rgba(17,136,247,0.4)" stroke-width="1.2" marker-end="url(#arr)"/>
        <path d="M428,71 C412,42 468,42 452,71" fill="none" stroke="rgba(17,136,247,0.4)" stroke-width="1.2" marker-end="url(#arr)"/>
        <path d="M568,71 C552,42 608,42 592,71" fill="none" stroke="rgba(17,136,247,0.4)" stroke-width="1.2" marker-end="url(#arr)"/>
        <text x="160" y="37" text-anchor="middle" font-size="7.5" fill="rgba(255,225,158,0.55)">aᵢᵢ</text>
        <text x="300" y="37" text-anchor="middle" font-size="7.5" fill="rgba(255,225,158,0.55)">aᵢᵢ</text>
        <text x="440" y="37" text-anchor="middle" font-size="7.5" fill="rgba(255,225,158,0.55)">aᵢᵢ</text>
        <text x="580" y="37" text-anchor="middle" font-size="7.5" fill="rgba(255,225,158,0.55)">aᵢᵢ</text>

        <!-- ── emission arrows ── -->
        <line x1="160" y1="147" x2="160" y2="198" stroke="rgba(122,204,255,0.45)" stroke-width="1.2" stroke-dasharray="4,3" marker-end="url(#arr-emit)"/>
        <line x1="300" y1="147" x2="300" y2="198" stroke="rgba(122,204,255,0.45)" stroke-width="1.2" stroke-dasharray="4,3" marker-end="url(#arr-emit)"/>
        <line x1="440" y1="147" x2="440" y2="198" stroke="rgba(122,204,255,0.45)" stroke-width="1.2" stroke-dasharray="4,3" marker-end="url(#arr-emit)"/>
        <line x1="580" y1="147" x2="580" y2="198" stroke="rgba(122,204,255,0.45)" stroke-width="1.2" stroke-dasharray="4,3" marker-end="url(#arr-emit)"/>
        <text x="148" y="176" font-size="7.5" fill="rgba(122,204,255,0.5)">b(oₜ)</text>
        <text x="288" y="176" font-size="7.5" fill="rgba(122,204,255,0.5)">b(oₜ)</text>
        <text x="428" y="176" font-size="7.5" fill="rgba(122,204,255,0.5)">b(oₜ)</text>
        <text x="568" y="176" font-size="7.5" fill="rgba(122,204,255,0.5)">b(oₜ)</text>

        <!-- ── observation nodes ── -->
        <rect x="122" y="200" width="76" height="28" rx="6" fill="rgba(122,204,255,0.07)" stroke="rgba(122,204,255,0.25)" stroke-width="1"/>
        <text x="160" y="218" text-anchor="middle" font-size="9" fill="rgba(235,241,255,0.6)">acoustic frame</text>

        <rect x="262" y="200" width="76" height="28" rx="6" fill="rgba(122,204,255,0.07)" stroke="rgba(122,204,255,0.25)" stroke-width="1"/>
        <text x="300" y="218" text-anchor="middle" font-size="9" fill="rgba(235,241,255,0.6)">acoustic frame</text>

        <rect x="402" y="200" width="76" height="28" rx="6" fill="rgba(122,204,255,0.07)" stroke="rgba(122,204,255,0.25)" stroke-width="1"/>
        <text x="440" y="218" text-anchor="middle" font-size="9" fill="rgba(235,241,255,0.6)">acoustic frame</text>

        <rect x="542" y="200" width="76" height="28" rx="6" fill="rgba(122,204,255,0.07)" stroke="rgba(122,204,255,0.25)" stroke-width="1"/>
        <text x="580" y="218" text-anchor="middle" font-size="9" fill="rgba(235,241,255,0.6)">acoustic frame</text>

        <!-- legend -->
        <line x1="20" y1="248" x2="44" y2="248" stroke="rgba(17,136,247,0.7)" stroke-width="1.4" marker-end="url(#arr)"/>
        <text x="48" y="252" font-size="8" fill="rgba(235,241,255,0.38)">transition prob aᵢⱼ</text>
        <line x1="160" y1="248" x2="184" y2="248" stroke="rgba(122,204,255,0.5)" stroke-width="1.2" stroke-dasharray="4,3" marker-end="url(#arr-emit)"/>
        <text x="188" y="252" font-size="8" fill="rgba(235,241,255,0.38)">emission prob b(oₜ)</text>
        <circle cx="330" cy="248" r="5" fill="none" stroke="rgba(17,136,247,0.55)" stroke-width="1.5"/>
        <text x="340" y="252" font-size="8" fill="rgba(235,241,255,0.38)">hidden phoneme state</text>
      </svg>
    </div>

    <p>Word Error Rate measures transcription quality using minimum edit distance (Levenshtein distance) between the reference and hypothesis, counting substitutions, deletions, and insertions, normalized by total reference tokens. SpeechWrite applies this at the phoneme level rather than the word level, giving granular signal about which specific sounds drive errors.</p>

    <!-- WER equation -->
    <div class="eq-block">
      <div class="eq-label">Word / Phoneme Error Rate</div>
      <div class="eq-main">
        <span class="hl">WER</span> &nbsp;=&nbsp;
        <span class="eq-frac">
          <span class="eq-num"><span class="yl">S</span> + <span class="yl">D</span> + <span class="yl">I</span></span>
          <span class="eq-den">N</span>
        </span>
      </div>
      <div class="eq-desc">
        <span>S</span> = substitutions &nbsp;·&nbsp;
        <span>D</span> = deletions &nbsp;·&nbsp;
        <span>I</span> = insertions (excluded at phoneme level) &nbsp;·&nbsp;
        <span>N</span> = total reference tokens
      </div>
    </div>
    <p>Our pipeline calls Whisper five times per clip and accumulates the WER on each pass. Averaging across runs gives a more stable estimate than a single inference pass, reducing the effect of any one decode being unusually good or bad.</p>

      <!-- Averaging equation -->
      <div class="eq-block">
        <div class="eq-label">Averaged WER per clip</div>
        <div class="eq-main">
          <span class="hl">WER<sub style="font-size:.6em">avg</sub></span> &nbsp;=&nbsp;
          <span class="eq-frac">
            <span class="eq-num"><span class="yl">∑</span> WER<sub style="font-size:.6em">i</sub></span>
            <span class="eq-den">n</span>
          </span>
          &nbsp;=&nbsp;
          <span class="eq-frac">
            <span class="eq-num">error_sum</span>
            <span class="eq-den">5</span>
          </span>
        </div>
        <div class="eq-desc">
          <span>n = 5</span> inference runs per clip &nbsp;·&nbsp;
          <span>error_sum</span> accumulated across runs in <code style="color:rgba(122,204,255,.7);font-size:10px">generate_simple_csv.py</code>
        </div>
      </div>

    <p>Per-phoneme error counts accumulate into a frequency table. For each clip we walk the aligned phoneme pairs, increment the phoneme's total count, and if the pair is a substitution or deletion we also increment its error count. Both counters are subdivided by accent tag, so the table supports queries like "how often is AE deleted in Indian English" — which is the per-accent bias signal the dashboard visualizes.</p>
    <p>Together, stable averaged WER and per-phoneme error rates broken out by accent give teams a phoneme-resolution map of model bias: which sounds are reliably recognized, which are accent-sensitive, and which the model fails across all groups.</p>
  </div>

</main>

</body>
</html>